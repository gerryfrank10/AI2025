{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/gerryfrank10/AI2025/blob/main/Understanding_PyTorch_Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
   "id": "9da9ca7633952275"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# How we will learn PyTorch\n",
    "1. First, we are going to cover PyTorch’s programming model, in particular, creating and manipulating tensors.\n",
    "2. Then, we will see how to load data and utilize the torch.utils.data module, which will allow us to iterate through a dataset efficiently. In addition, we will discuss the existing, ready-to-use datasets in the torch.utils.data.Dataset submodule and learn how to use them.\n",
    "3. After learning about these basics, the PyTorch neural network torch.nn module will be introduced.\n",
    "4. Then, we will move forward to building machine learning models, learn how to compose and train the models, and learn how to save the trained models on disk for future evaluation."
   ],
   "id": "5cec67e97878a933"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# First steps with PyTorch\n",
    "\n",
    "Now, we will take our first steps in using the low-level PyTorch API. After installing PyTorch, we will cover how to create tensors in PyTorch and different ways of manipulating them, such as changing their shape, data type, and so on."
   ],
   "id": "59bbbef5734415de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Installing PyTorch\n",
    "To install PyTorch, we recommend consulting the latest instructions on the official https://pytorch.org\n",
    "website.\n",
    "\n",
    "Below, we will outline the basic steps that will work on most systems.\n",
    "Depending on how your system is set up, you can typically just use Python’s pip installer and install PyTorch from PyPI by executing the following from your terminal:\n",
    "\n",
    "    pip install torch torchvision\n",
    "\n",
    "For example, I will be instally 1.9.0 version (it can be modified according to requirments)"
   ],
   "id": "b72d096526ada964"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install torch==2.0.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118",
   "id": "aae1ae89eb5b52b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can also install torch as follows:",
   "id": "718a9d483d2dce7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install torch",
   "id": "38a8620f8b2d3c68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Checking PyTorch Version",
   "id": "ee58c54a37d340ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ],
   "id": "399c441117a992e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install numpy",
   "id": "d26abde276de4627"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Creating tensors in PyTorch\n",
    "\n",
    "Now, let’s consider a few different ways of creating tensors, and then see some of their properties and how to manipulate them.\n",
    "\n",
    "Firstly, we can simply create a tensor from a list or a NumPy array using the torch.tensor or the torch.from_numpy function as follows:\n"
   ],
   "id": "ae13565b2084abac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np # This imports numpy\n",
    "import torch\n",
    "\n",
    "a = [1, 2, 3]\n",
    "#b = np.array([4, 5, 6], dtype=np.int32) # This uses numpy to create an array\n",
    "np.set_printoptions(precision=3)\n",
    "t_a = torch.tensor(a)\n",
    "#t_b = torch.from_numpy(b) # This converts the numpy array to a torch tensor\n",
    "\n",
    "print(t_a)\n",
    "#print(t_b)"
   ],
   "id": "f1072f78d04c42ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creating a tensor of random values can be done as follows:",
   "id": "24613c5c541ce09d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rand_tensor = torch.rand(2,3)\n",
    "\n",
    "print(rand_tensor)"
   ],
   "id": "2a190acc2e477146"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Manipulating the data type and shape of a tensor\n",
    "Learning ways to manipulate tensors is necessary to make them compatible for input to a model or an operation. Now, you will learn how to manipulate tensor data types and shapes via several PyTorch functions that cast, reshape, transpose, and squeeze (remove dimensions)."
   ],
   "id": "bee5b313e0077b96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The torch.to() function can be used to change the data type of a tensor to a desired type:",
   "id": "1bae4f9dc3ccb757"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "t_a_new = t_a.to(torch.int64)\n",
    "\n",
    "print(t_a_new.dtype)"
   ],
   "id": "2600ca7ae417c8a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transposing a tensor:",
   "id": "a4cedb083f680df2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "t = torch.rand(3, 5)\n",
    "\n",
    "t_tr = torch.transpose(t, 0, 1)\n",
    "print(t.shape, ' --> ', t_tr.shape)"
   ],
   "id": "4730553176d33caf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reshaping a tensor (for example, from a 1D vector to a 2D array):",
   "id": "89d2673b85ae1435"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "t = torch.zeros(30)\n",
    "\n",
    "t_reshape = t.reshape(5, 6)\n",
    "\n",
    "print(t_reshape.shape)"
   ],
   "id": "d50cf14242e1f0c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Removing the unnecessary dimensions (dimensions that have size 1, which are not needed):",
   "id": "3b82cc3f6b0915c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "t = torch.zeros(1, 2, 1, 4, 1)\n",
    "\n",
    "t_sqz = torch.squeeze(t, 2)\n",
    "\n",
    "print(t.shape, ' --> ', t_sqz.shape)"
   ],
   "id": "485cbe5fc8544b37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Applying mathematical operations to tensors",
   "id": "bf6a60cb18f7fbec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, let’s instantiate two random tensors, one with uniform distribution in the range [–1, 1) and the other with a standard normal distribution:",
   "id": "a27b4796b0ebf9e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "t1 = 2 * torch.rand(5, 2) - 1\n",
    "t2 = torch.normal(mean=0, std=1, size=(5, 2))"
   ],
   "id": "5dda80122a5366a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note that torch.rand returns a tensor filled with random numbers from a uniform distribution in the range of [0, 1).\n",
    "\n",
    "Notice that t1 and t2 have the same shape. Now, to compute the element-wise product of t1 and t2, we can use the following:"
   ],
   "id": "97209c82b3707b0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "t3 = torch.multiply(t1, t2)\n",
    "print(t3)"
   ],
   "id": "94ca5f61184da4c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Computin mean, sum and standard deviation:\n",
    "\n",
    "To compute the mean, sum, and standard deviation along a certain axis (or axes), we can use torch.mean(), torch.sum(), and torch.std(). For example, the mean of each column in t1 can be computed as follows:"
   ],
   "id": "d66dccfcec3d9197"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "t4 = torch.mean(t1, axis=0)\n",
    "print(t4)"
   ],
   "id": "9617eded148c9e9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The matrix-matrix product between t1 and t2 can be computed by using the torch.matmul() function as follows:",
   "id": "194170748325f7a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "t5 = torch.matmul(t1, torch.transpose(t2, 0, 1))\n",
    "\n",
    "print(t5)"
   ],
   "id": "f68449ad24e5e7a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# On the other hand, computing transpose of t1 and multiply with t2 is performed by transposing t1, resulting in an array of size 2×2:",
   "id": "6a410e47f41e16d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "t6 = torch.matmul(torch.transpose(t1, 0, 1), t2)\n",
    "\n",
    "print(t6)"
   ],
   "id": "5cd7bae13d5fa353"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Split, stack, and concatenate tensors\n",
    "\n",
    "Now, we will cover PyTorch operations for splitting a tensor into multiple tensors, or the reverse: stacking and concatenating multiple tensors into a single one.\n",
    "\n",
    "Assume that we have a single tensor, and we want to split it into two or more tensors. For this, PyTorch provides a convenient **torch.chunk()** function, which divides an input tensor into a list of equally sized tensors. We can determine the desired number of splits as an integer using the chunks argument\n",
    "to split a tensor along the desired dimension specified by the dim argument. In this case, the total size of the input tensor along the specified dimension must be divisible by the desired number of splits. Alternatively, we can provide the desired sizes in a list using the torch.split() function. Let’s have a look at an example of both these options:"
   ],
   "id": "3c0120221a82edf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Providing the number of splits:",
   "id": "dcf56fbcdbf913a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "t = torch.rand(6)\n",
    "\n",
    "print(t)\n",
    "#import torch\n",
    "t_splits = torch.chunk(t, 3)\n",
    "\n",
    "[item.numpy() for item in t_splits]"
   ],
   "id": "1266909b3206c47d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this example, a tensor of size 6 was divided into a list of three tensors each with size 2. If the tensor size is not divisible by the chunks value, the last chunk will be smaller.",
   "id": "330f9e061d16bfd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "t = torch.rand(8)\n",
    "\n",
    "print(t)\n",
    "#import torch\n",
    "t_splits = torch.chunk(t, 3)\n",
    "\n",
    "[item.numpy() for item in t_splits]"
   ],
   "id": "cbfdf88a3a0f0c00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Providing the sizes of different splits:\n",
    "Alternatively, instead of defining the number of splits, we can also specify the sizes of the\n",
    "output tensors directly. Here, we are splitting a tensor of size 5 into tensors of sizes 3 and 2:"
   ],
   "id": "db6f01385c7491d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(1)\n",
    "t = torch.rand(5)\n",
    "\n",
    "print(t)\n",
    "\n",
    "t_splits = torch.split(t, split_size_or_sections=[3, 2])\n",
    "\n",
    "[item.numpy() for item in t_splits]"
   ],
   "id": "33a5695894dd1eb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Stacking Tensors\n",
    "\n",
    "Sometimes, we are working with multiple tensors and need to concatenate or stack them to create a single tensor. In this case, PyTorch functions such as torch.stack() and torch.cat() come in handy.\n",
    "\n",
    "For example, let’s create a 1D tensor, A, containing 1s with size 3, and a 1D tensor, B, containing 0s with size 2, and concatenate them into a 1D tensor, C, of size 5:"
   ],
   "id": "89381c24300e0627"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "A = torch.ones(3)\n",
    "B = torch.zeros(2)\n",
    "\n",
    "C = torch.cat([A, B], axis=0)\n",
    "print(C)"
   ],
   "id": "3df69a3531f85ddf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we create 1D tensors A and B, both with size 3, then we can stack them together to form a 2D tensor, S:",
   "id": "476604aca2d39bf4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "A = torch.ones(3)\n",
    "B = torch.zeros(3)\n",
    "\n",
    "S = torch.stack([A, B], axis=1)\n",
    "print(S)"
   ],
   "id": "255add2aa4418f71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The PyTorch API has many operations that you can use for building a model, processing your data, and more. However, covering every function is not possible, where we will focus on the most essential ones. For the full list of operations and functions, you can refer to the documentation\n",
    "page of PyTorch at https://pytorch.org/docs/stable/index.html."
   ],
   "id": "2c4a26886298153"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Building input pipelines in PyTorch",
   "id": "4b9a8c3df5fb19db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Creating a PyTorch DataLoader from existing tensors\n",
    "If the data already exists in the form of a tensor object, a Python list, or a NumPy array, we can easily create a dataset loader using the torch.utils.data.DataLoader() class. It returns an object of the DataLoader class, which we can use to iterate through the individual elements in the input dataset. As\n",
    "a simple example, consider the following code, which creates a dataset from a list of values from 0 to 5:"
   ],
   "id": "f602d957081d3a77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "t = torch.arange(6, dtype=torch.float32)\n",
    "data_loader = DataLoader(t)"
   ],
   "id": "fc02792cfe551cdb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can easily iterate through a dataset entry by entry as follows:",
   "id": "62433c22ede6fc70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for item in data_loader:\n",
    "    print(item)"
   ],
   "id": "41f1aaa7b98ea6a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we want to create batches from this dataset, with a desired batch size of 3, we can do this with the batch_size argument as follows:",
   "id": "28190f7e96712851"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_loader = DataLoader(t, batch_size=3, drop_last=False)\n",
    "\n",
    "for i, batch in enumerate(data_loader, 1):\n",
    "    print(f'batch {i}:', batch)"
   ],
   "id": "76272be8de3f71af"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This will create two batches from this dataset, where the first three elements go into batch #1, and the remaining elements go into batch #2. The optional drop_last argument is useful for cases when the number of elements in the tensor is not divisible by the desired batch size. We can drop the last\n",
    "non-full batch by setting drop_last to True. The default value for drop_last is False.\n",
    "\n",
    "We can always iterate through a dataset directly, but as you just saw, DataLoader provides an automatic and customizable batching to a dataset."
   ],
   "id": "704152354ac0fe5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Combining two tensors into a joint dataset\n",
    "\n",
    "Often, we may have the data in two (or possibly more) tensors. For example, we could have a tensor for features and a tensor for labels. In such cases, we need to build a dataset that combines these tensors, which will allow us to retrieve the elements of these tensors in tuples."
   ],
   "id": "da78ed997937c8ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Assume that we have two tensors, t_x and t_y. Tensor t_x holds our feature values, each of size 3, and t_y stores the class labels. For this example, we first create these two tensors as follows:",
   "id": "3b63fa26f05db763"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(1)\n",
    "t_x = torch.rand([4, 3], dtype=torch.float32)\n",
    "#print(t_x)\n",
    "t_y=torch.arange(4)\n",
    "#print(t_y)"
   ],
   "id": "76d4cceaeaa95ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we want to create a joint dataset from these two tensors. We first need to create a Dataset class as follows:",
   "id": "404f4f8d3ba1e6ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class JointDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ],
   "id": "7eae9c6eac1a97ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A custom Dataset class must contain the following methods to be used by the data loader later on:\n",
    "\n",
    "• __init__(): This is where the initial logic happens, such as reading existing arrays, loading a file, filtering data, and so forth.\n",
    "\n",
    "• __getitem__(): This returns the corresponding sample to the given index."
   ],
   "id": "b7430e040192ff2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then we create a joint dataset of t_x and t_y with the custom Dataset class as follows:",
   "id": "a99a2a9c38a98dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "t_x = torch.rand([4, 3], dtype=torch.float32)\n",
    "t_y = torch.arange(4)\n",
    "joint_dataset = JointDataset(t_x, t_y)\n",
    "\n",
    "# Or use TensorDataset directly\n",
    "# from torch.utils.data import TensorDataset\n",
    "# joint_dataset = TensorDataset(t_x, t_y)\n",
    "\n",
    "for example in joint_dataset:\n",
    "    print('  x: ', example[0],\n",
    "          '  y: ', example[1])"
   ],
   "id": "eef2b07533075004"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Shuffle, batch, and repeat\n",
    "\n",
    "As discussed, training Machine Learning Algorithms for Classification, when\n",
    "training an NN model using stochastic gradient descent optimization, it is important to feed training data as randomly shuffled batches.\n",
    "\n",
    "You have already seen how to specify the batch size using the batch_size argument of a data loader object. Now, in addition to creating batches, you will see how to shuffle and reiterate over the datasets. We will continue working with the previous joint dataset."
   ],
   "id": "793edf4e37de3d03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, let’s create a shuffled version data loader from the joint_dataset dataset:",
   "id": "a123f106b4605206"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(1)\n",
    "data_loader = DataLoader(dataset=joint_dataset, batch_size=2, shuffle=True)"
   ],
   "id": "cdef261dbd4bc4e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, each batch contains two data records (x) and the corresponding labels (y). Now we iterate through the data loader entry by entry as follows:",
   "id": "e20582a75755a67d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for i, batch in enumerate(data_loader, 1):\n",
    "        print(f'batch {i}:', 'x:', batch[0],\n",
    "              '\\n         y:', batch[1])"
   ],
   "id": "3aed149a446e5c0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The rows are shuffled without losing the one-to-one correspondence between the entries in x and y.",
   "id": "d367c71d02d49e59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In addition, when training a model for multiple epochs, we need to shuffle and iterate over the dataset by the desired number of epochs. So, let’s iterate over the batched dataset twice:",
   "id": "737b11676b5f5a69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for epoch in range(2):\n",
    "    print(f'epoch {epoch+1}')\n",
    "    for i, batch in enumerate(data_loader, 1):\n",
    "        print(f'batch {i}:', 'x:', batch[0],\n",
    "              '\\n         y:', batch[1])"
   ],
   "id": "5676fe20b7ccc320"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This results in two different sets of batches. In the first epoch, the first batch contains a pair of values [y=1, y=2], and the second batch contains a pair of values [y=3, y=0]. In the second epoch, two batches contain a pair of values, [y=2, y=0] and [y=1, y=3] respectively. For each iteration, the elements within a batch are also shuffled",
   "id": "b3845a7fafeec42a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Creating a dataset from files on your local storage disk\n",
    "\n",
    "Now, we will build a dataset from image files stored on disk. There is an image folder associated with the online content of this chapter. After downloading the folder, you should be able to see six images of cats and dogs in JPEG format.This small dataset will show how building a dataset from stored files generally works.\n",
    "\n",
    "To accomplish this, we are going to use two additional modules: Image in PIL to read the image file contents and transforms in torchvision to decode the raw contents and resize the images."
   ],
   "id": "34e0374fc720b220"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Before we start, let’s take a look at the content of these files. We will use the pathlib library to generate a list of image files:",
   "id": "dd4299afc7571b31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pathlib\n",
    "\n",
    "imgdir_path = pathlib.Path('cat_dog_images')\n",
    "\n",
    "file_list = sorted([str(path) for path in imgdir_path.glob('*.jpg')])\n",
    "\n",
    "print(file_list)"
   ],
   "id": "db9e52363638d68f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we will visualize these image examples using Matplotlib:",
   "id": "bbd72f0b96dfbb3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i, file in enumerate(file_list):\n",
    "    img = Image.open(file)\n",
    "    print('Image shape: ', np.array(img).shape)\n",
    "    ax = fig.add_subplot(2, 3, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(os.path.basename(file), size=15)\n",
    "\n",
    "#plt.savefig('figures/12_03.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "7d7e8a89e6647cc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Just from this visualization and the printed image shapes, we can already see that the images have different aspect ratios. If you print the aspect ratios (or data array shapes) of these images, you will see that some images are 900 pixels high and 1200 pixels wide (900×1200), some are 800×1200, and one is\n",
    "900×742. Later, we will preprocess these images to a consistent size.\n",
    "\n",
    "Another point to consider is that the labels for these images are provided within their filenames. So, we extract these labels from the list of filenames, assigning label 1 to dogs and label 0 to cats:"
   ],
   "id": "aea65180bb525811"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "labels = [1 if 'dog' in os.path.basename(file) else 0\n",
    "          for file in file_list]\n",
    "print(labels)"
   ],
   "id": "5cb532dc43202774"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we have two lists: a list of filenames (or paths of each image) and a list of their labels.\n",
    "\n",
    "In the previous section, you learned how to create a joint dataset from two arrays. Here, we will do the following"
   ],
   "id": "76f482f3a6cea93d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.utils.data import Dataset  # Importing the Dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_list, labels):\n",
    "        self.file_list = file_list\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file = self.file_list[index]\n",
    "        label = self.labels[index]\n",
    "        return file, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "image_dataset = ImageDataset(file_list, labels)\n",
    "for file, label in image_dataset:\n",
    "    print(file, label)"
   ],
   "id": "4a4a89a88a5399a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The joint dataset has filenames and labels.",
   "id": "773a8f1e4ba66d4b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next, we need to apply transformations to this dataset: load the image content from its file path, decode the raw content, and resize it to a desired size, for example, 80×120. As mentioned before, we use the\n",
    "\n",
    "    torchvision.transforms\n",
    "\n",
    "module to resize the images and convert the loaded pixels into tensors as follows:\n",
    "\n",
    "    import torchvision.transforms as transforms\n",
    "    img_height, img_width = 80, 120\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    ])\n"
   ],
   "id": "9d4dc4ada0ca201c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_list, labels, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.file_list[index])\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "img_height, img_width = 80, 120\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "])\n",
    "\n",
    "image_dataset = ImageDataset(file_list, labels, transform)"
   ],
   "id": "b91d2fd017606f9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, we visualize these transformed image examples using Matplotlib:",
   "id": "bb89995ec4691cfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "for i, example in enumerate(image_dataset):\n",
    "    ax = fig.add_subplot(2, 3, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(example[0].numpy().transpose((1, 2, 0)))\n",
    "    ax.set_title(f'{example[1]}', size=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('figures/12_04.pdf')\n",
    "plt.show()"
   ],
   "id": "a9c40b8bbd2f7a54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The __getitem__ method in the ImageDataset class wraps all four steps into a single function, including\n",
    "the loading of the raw content (images and labels), decoding the images into tensors, and resizing the\n",
    "images. The function then returns a dataset that we can iterate over and apply other operations that\n",
    "we learned about in the previous sections via a data loader, such as shuffling and batching"
   ],
   "id": "547e799d73f7023b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fetching available datasets from the torchvision.datasets library\n",
    "\n",
    "The\n",
    "\n",
    "    torchvision.datasets\n",
    "\n",
    "library provides a nice collection of freely available image datasets for\n",
    "training or evaluating deep learning models. Similarly, the\n",
    "\n",
    "    torchtext.datasets\n",
    "\n",
    "library provides datasets for natural language. Here, we use\n",
    "\n",
    "    torchvision.datasets\n",
    "\n",
    "as an example.\n",
    "\n",
    "The torchvision datasets (https://pytorch.org/vision/stable/datasets.html) are nicely formatted and come with informative descriptions, including the format of features and labels and their type and dimensionality, as well as the link to the original source of the dataset.\n",
    "\n",
    "Another advantage is that these datasets are all subclasses of\n",
    "\n",
    "    torch.utils.data.Dataset\n",
    "\n",
    "So all the functions we covered in the previous sections can be used directly.\n",
    "\n",
    "So, let’s see how to use these datasets in action."
   ],
   "id": "99244d5cda27f58e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, if you haven’t already installed torchvision together with PyTorch earlier, you need to install the torchvision library via pip from the command line:",
   "id": "145373f818551c04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pip install torchvision",
   "id": "ca32664ae6c34d19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can take a look at the list of available datasets at https://pytorch.org/vision/stable/datasets.html",
   "id": "15b401767a66859c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# In the following paragraphs, we will cover fetching two different datasets: CelebA (celeb_a) and the MNIST digit dataset.\n",
    "\n"
   ],
   "id": "e73bce2c2b0fc6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import torchvision",
   "id": "db4967df5b8c0317"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You can take a look at the list of available datasets at https://pytorch.org/vision/stable/datasets.\n",
    "html.\n",
    "\n",
    "In the following paragraphs, we will cover fetching two different datasets: CelebA (celeb_a) and the\n",
    "MNIST digit dataset.\n",
    "\n",
    "Let’s first work with the CelebA dataset (http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) with\n",
    "torchvision.datasets.CelebA (https://pytorch.org/vision/stable/datasets.html#celeba). The\n",
    "description of torchvision.datasets.CelebA provides some useful information to help us understand\n",
    "the structure of this dataset:\n",
    "\n",
    "• The database has three subsets, 'train', 'valid', and 'test'. We can select a specific subset\n",
    "or load all of them with the split parameter.\n",
    "\n",
    "• The images are stored in PIL.Image format. And we can obtain a transformed version using a\n",
    "custom transform function, such as transforms.ToTensor and transforms.Resize.\n",
    "\n",
    "• There are different types of targets we can use, including 'attributes', 'identity', and\n",
    "'landmarks'. 'attributes' is 40 facial attributes for the person in the image, such as facial\n",
    "expression, makeup, hair properties, and so on; 'identity' is the person ID for an image;\n",
    "and 'landmarks' refers to the dictionary of extracted facial points, such as the position of the\n",
    "eyes, nose, and so on.\n"
   ],
   "id": "b91e0c5f0b08c6d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next, we will call the\n",
    "\n",
    "    torchvision.datasets.CelebA\n",
    "\n",
    "class to download the data, store it on disk in a\n",
    "designated folder, and load it into a torch.utils.data.Dataset object:"
   ],
   "id": "774a00e88a8e9a74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "image_path = '../'\n",
    "celeba_dataset = torchvision.datasets.CelebA(\n",
    "    image_path, split='train', target_type='attr', download=True)"
   ],
   "id": "de1942d04377fa52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You may run into a BadZipFile: File is not a zip file error, or RuntimeError: The daily quota\n",
    "of the file img_align_celeba.zip is exceeded and it can't be downloaded. This is a\n",
    "limitation of Google Drive and can only be overcome by trying again later; it just means\n",
    "that Google Drive has a daily maximum quota that is exceeded by the CelebA files.\n",
    "\n",
    "To work around it, you can manually download the files from the source: http://mmlab.ie.cuhk.edu.hk/projects/\n",
    "CelebA.html. In the downloaded folder, celeba/, you can unzip the img_align_celeba.zip file. The\n",
    "image_path is the root of the downloaded folder, celeba/. If you have already downloaded the files\n",
    "once, you can simply set download=False."
   ],
   "id": "1b2282aaedcc0003"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now that we have instantiated the datasets, let’s check if the object is of the torch.utils.data.Dataset\n",
    "class:"
   ],
   "id": "1152cce38004497"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "assert isinstance(celeba_dataset, torch.utils.data.Dataset)",
   "id": "a49c199df5007ecc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As mentioned, the dataset is already split into train, test, and validation datasets, and we only load the\n",
    "train set. And we only use the 'attributes' target. In order to see what the data examples look like,\n",
    "we can execute the following code:"
   ],
   "id": "430a4c8cd8660cc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "example = next(iter(celeba_dataset))\n",
    "print(example)"
   ],
   "id": "139c8b69ecbd8b61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note that the sample in this dataset comes in a tuple of (PIL.Image, attributes). If we want to pass\n",
    "this dataset to a supervised deep learning model during training, we have to reformat it as a tuple of\n",
    "(features tensor, label). For the label, we will use the 'Smiling' category from the attributes as\n",
    "an example, which is the 31st element."
   ],
   "id": "2d88efda1e24f166"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, let’s take the first 18 examples from it to visualize them with their 'Smiling' labels:",
   "id": "6a55c7a11b805d09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from itertools import islice\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "for i, (image, attributes) in islice(enumerate(celeba_dataset), 18):\n",
    "    ax = fig.add_subplot(3, 6, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(f'{attributes[31]}', size=15)\n",
    "\n",
    "#plt.savefig('figures/12_05.pdf')\n",
    "plt.show()"
   ],
   "id": "59b53558bcf2acf0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MNIST Database Using PyTorch:\n",
    "\n",
    "Next, we will proceed with the second dataset from torchvision.datasets.MNIST (https://pytorch.\n",
    "org/vision/stable/datasets.html#mnist).\n",
    "\n",
    "Let’s see how it can be used to fetch the MNIST digit dataset:\n",
    "\n",
    "• The database has two partitions, 'train' and 'test'. We need to select a specific subset to load.\n",
    "\n",
    "• The images are stored in PIL.Image format. And we can obtain a transformed version using a\n",
    "custom transform function, such as transforms.ToTensor and transforms.Resize.\n",
    "\n",
    "• There are 10 classes for the target, from 0 to 9."
   ],
   "id": "b76864f86f4cccc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from itertools import islice # Import islice from itertools\n",
    "mnist_dataset = torchvision.datasets.MNIST(image_path, 'train', download=True)\n",
    "\n",
    "assert isinstance(mnist_dataset, torch.utils.data.Dataset)\n",
    "\n",
    "example = next(iter(mnist_dataset))\n",
    "print(example)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i, (image, label) in islice(enumerate(mnist_dataset), 10):\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(image, cmap='gray_r')\n",
    "    ax.set_title(f'{label}', size=15)\n",
    "\n",
    "plt.show()"
   ],
   "id": "ae6fb18435d3390d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Summary:\n",
    "\n",
    "This concludes our coverage of building and manipulating datasets and fetching datasets from the\n",
    "\n",
    "    torchvision.datasets\n",
    "\n",
    "library.\n"
   ],
   "id": "40562a2f5c7b8477"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
